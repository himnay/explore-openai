==========
Prompt 1: |
==========

I am going to give you a streamlit chatbot code. Please load the whole code into the editor, dont modify it.
I am going to give you a streamlit chatbot code. 

```
<paste your code here>
```
==========
Prompt 2: |
==========

This chatbot has multi-modal capabilities. The chatbot can handle text and images and reason them using LLM.
Now I would like to add the the new multi-modal capability of dealing with audio files.
1 - Enhance this chatbot to have the ability to upload the audio files.
  - Do not remove any of the existing capabilities text and image processing of the chatbot.
  - Display the audio file in the UI.
  - Save the audio file in the DB for storing and retrieving them and display it in the UI.
  - If audio file or both audio file and prompt are given then pass it to the ask_openai_audio function given below.
  - Always make sure to use **client.audio.transcriptions.create** api for processing the audio file.


```
# Call the openai chat.completions endpoint
client = OpenAI()

def ask_openai_audio(
    audio_path: str,
    prompt : str = ""
) -> Transcription:
    
    print(f"LLM : {LLM}")
    #The "rb" stands for read binary mode. Here's what it means:
    #  "r" (read mode): This opens the file for reading. The file must exist for this mode, and its contents cannot be modified.
    #  "b" (binary mode): This tells Python to open the file in binary mode, meaning the file is read as raw binary data, rather than as a text file.
    

    audio_file= open(audio_path, "rb")

    transcription = client.audio.transcriptions.create(
    model="whisper-1", 
    prompt = prompt,
    file=audio_file
    )
    print(f"Response Type : {type(transcription)}")

    return transcription  
```    